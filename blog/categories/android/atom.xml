<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: android | Solarex's Blog]]></title>
  <link href="http://Solarex.github.io/blog/categories/android/atom.xml" rel="self"/>
  <link href="http://Solarex.github.io/"/>
  <updated>2016-12-29T09:57:49+08:00</updated>
  <id>http://Solarex.github.io/</id>
  <author>
    <name><![CDATA[Solarex]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Mobile Apps Offline Support]]></title>
    <link href="http://Solarex.github.io/blog/2016/03/14/mobile-apps-offline-support/"/>
    <updated>2016-03-14T08:43:00+08:00</updated>
    <id>http://Solarex.github.io/blog/2016/03/14/mobile-apps-offline-support</id>
    <content type="html"><![CDATA[<p>Offline support for mobile applications can be thought of as the ability for the application to react gracefully to the lack of stability of the network connection. The rather new context of mobile devices introduced problems such as presence or absence of a network connection or even high latency and low bandwidth. These problems are rather new and thus not very well known to engineers starting with mobile development. Among other things building a mobile application which resilient to different network scenarios could mean:</p>

<ul>
<li>Displaying comprehensive error messages when network calls fail.</li>
<li>Allowing the use of the application in “guest mode”, where certain features can be delayed until the user actually signs in.</li>
<li>Visually displaying the absence of network connectivity on the UI (connected mode/offline mode).</li>
<li>Disabling controls in the absence of network connectivity.</li>
<li>Allowing the user to query and act on data while no network connection (offline data access).</li>
<li>Testing the application under different network conditions!</li>
</ul>


<p>While all these things are extremely important from the usability point of view, there is one of these that can be particular complex, “offline data access”. There are several different scenarios or levels of offline data access that applications might need to support, and I’ll go through each next.</p>

<!-- more -->


<h2>Local Caching</h2>

<p>The application needs to be able to display information even when there is no connection, however under connectivity conditions the data needs to be refreshed. This is achieved by somehow persisting the data on the mobile device, usually for a healthy period of time.</p>

<center><img src="http://Solarex.github.io/images/local_cache.png"></center>


<p>There are 3 different “strategies” for refreshing the data on the cache which I would like to cover next.</p>

<h3>Network first</h3>

<p>Always try to retrieve the data from the server, and whenever that is not possible, then resort to retrieve the data from the local cache. This strategy can be very useful if you are particularly interested in showing the latest and more updated information.</p>

<h3>Local first</h3>

<p>For a specified period of time, don’t even try to go the network, just return from local cache. This approach is very well suited when there’s no risk in showing cached data. On the other hand, it has a better user experience since there’s usually no latency involved.</p>

<h3>Hybrid / Smart</h3>

<p>This approach will return from local cache before fetching data from a service. It can either wait for a notification from the server or simply poll the service in background to refresh the data to cache it locally. This mechanism hits a balance between a good performance/UX, while still refreshing the local cache regularly, reducing the risk of showing “stale” data.</p>

<p>Furthermore, local caching can be complemented with some way of server-side caching support as well. Just as in HTTP caching, when retrieving the data from the server, the client can send a “revision” to see if the data has been updated. The server can check the clients revision against the current one on the server, and either inform the client that there is no need to update or return the latest data.</p>

<h3>Sample scenario</h3>

<p>The improvement in performance and user experience makes local caching extremely useful in many scenarios. The key condition for it to be useful is that the data does not have to be displayed in real-time. The longer the data can be locally cached, the more sense this approach will make.</p>

<p>Think for instance of a list of interesting locations or contacts for users on the “field”. This is information while very useful on the go, is unlikely to change very frequently, so it is ideal for being cached locally.</p>

<h2>Local Queuing</h2>

<p>Whenever the application does not have a network connection, server requests can be locally queued for later processing. This will allow the user to fire and forget operations and be notified whenever (and if) those operations were successfully processed by the server.</p>

<center><img src="http://Solarex.github.io/images/local_queuing.png"></center>


<p>When working with local queues of operations you should take into account the following things:</p>

<ul>
<li>Users should be notified that the operation has been queued.</li>
<li>Users will most probably be interested in seeing the actual status of the queue. Which are the items that went through and which are the ones that are still pending?</li>
<li>It could be important to be able to cancel or retry manually an operation while it is still in the queue.</li>
<li>Whenever one of these operations is sent to the server, the user will want to know the outcome (success, failed).</li>
<li>The flow or process the user initiated could potentially need to be resumed where it was left off at the time the operation was queued.</li>
</ul>


<p>Local queuing is particularly a good idea when having people doing auditing or field work like measuring things, and sending reports. If these operations are not updating records, but rather only inserting new ones, the implementation of this is rather simple and requires no concurrency management or conflict resolution.</p>

<h3>Sample Scenario</h3>

<p>Local queuing helps to not loose work while on the go. This can be extremely important in scenarios of inventory checks or audits, where the user on the field must not loose time waiting for a connection in order to use the app or submit those reports.</p>

<h3>Data-Sync</h3>

<p>By leveraging local caching and queuing, you can keep the data in your device and your server up to date. This is known as “synchronizing”. There are different ways to synchronize the data.</p>

<center><img src="http://Solarex.github.io/images/data_sync.png"></center>


<h3>Mobile Data up-to-date</h3>

<p>In this case, you worry about the data in you mobile application being up to date. This can be achieved in two ways: by just using local caching as described above, or it can be done by querying the server for the latest changes. These latest changes, also known as “delta”, allow the mobile application to apply and reconstruct the current state of the server. In order to be able to query for the latest changes, you can leverage audit fields like <code>UpdatedOn</code>, <code>CreatedOn</code> and <code>DeletedOn</code>.</p>

<p>In this second case, the data is not being modified in the device, so there is no need to resolve conflicts, so the server is always right.</p>

<h3>Server Data up-to-date</h3>

<p>This can be achieved by using local queues, but queuing is not enough. What happens if by the time my request is sent to the server, the data on the server was no longer in the same state as when I attempted to modify it? Delaying the execution of the request, for example due to network loss, can result in increased concurrency conflicts. At this point, the developer (or the user) must decide how to “merge” the changes on the server and the app. For every conflict in the data, the merge could be:</p>

<ul>
<li>Keep the device version</li>
<li>Keep the server version</li>
<li>Keep both versions</li>
</ul>


<p>More often than not, the logic for merging records can be automated by the mobile developer. Which algorithm is used, will be tied to the business rules of that application. Whenever this is not possible to fully automate, the user can be prompted to make a decision.</p>

<h3>Keep both Mobile and Server Up-to-date</h3>

<p>This is also referred to as two-way sync. As you can probably tell by now, this would be a combination of the two previous techniques. This is the most complete and powerful of the scenarios so far described. Notice however, that while it might be tempting to build applications to support two-way sync, it is by far the most complex scenario of all. Apart from being complex, as I have covered in this article, it might not always be necessary.</p>

<h3>Sample Scenario</h3>

<p>Two-way-sync gives the mobile application a whole new level of user experience. However, one of the key conditions for two-way sync to be a must-have is the need to keep a team or group of users up to date with everybody else’s activity. An example of such a thing could be collaborating applications with updates, comments or status changes. Think about a collaborative address book where everybody on the team is allowed to update contacts at any given time.</p>

<h2>Considerations</h2>

<p>Building your mobile application with support for offline scenarios, can drastically improve the user experience, however choosing the right level of support, and later on implementing this is not trivial. Below I will be listing some of the things to consider when planning to add offline support to your apps.</p>

<h3>Data Size</h3>

<p>When caching data locally, try to be conscious of the size of the data you’ll be storing. Striking the right balance between the amount of data that is stored and the perceived UX improvement is important. In cases where there are lots of data (ie: a full Sharepoint site), you might have to consider giving the user the option of choosing what he wants to cache for offline reading afterwards.</p>

<h3>Data Storage</h3>

<p>Make sure to choose wisely how and where you will be storing your data. Is that data sensitive? If so, you will want to encrypt the data while at rest (storage). If you choose to encrypt the data, make sure to also store the key for decrypting the data in a safe place and consider leveraging operating system functionality for this. Also keep in mind that in some platforms your application’s code can be read (or reflected), so consider obfuscating your code. And last but not least, make sure to have a mechanism for remotely wiping the data on the handset. Some tools like mobile device management (MDM) platforms can help to achieve this, but it can also be handled by the application itself.</p>

<h3>Battery Usage</h3>

<p>If you plan to have polling mechanisms and background jobs, make sure to take the battery status into account. Some processes and network usage might drain the battery in detriment of the user experience. You can check the status of the battery, and whether the device is connected to a charger before you start a rather consuming process.</p>

<h3>Consuming the Data</h3>

<p>Depending on your application’s needs, you might have to query and operate (create, update, delete) on your data. In non-trivial scenarios using a database as the persistence mechanism is not a bad idea. There are several things to take into account for choosing the right database:</p>

<ul>
<li>platform support: Will I be able to use this database from all the versions of my app? (iOS, Android, Web, Hybrid, etc…)</li>
<li>relational vs NoSQL database technology</li>
<li>ORM support for conveniently mapping the object model to the database</li>
<li>data size</li>
<li>existing support for sync protocols (ie: CouchDB)</li>
</ul>


<p>Next we will go through a list of libraries and databases that can be useful when implementing Offline Support.</p>

<h2>Useful Libraries &amp; Databases</h2>

<ul>
<li>SQLite,SQLite is an Open Source relational database that works very well in mobile devices. It uses a single file to store all the data, so managing the persistence side is simple. It will not solve too much on the sync- and conflict resolution side, but it’s a simple and easy to use alternative for caching or queuing information. There are implementations for the main mobile platforms like iOS, Android, Xamarin and Windows Phone.</li>
<li>SQLCypher,As previously said, when the data you are caching or queuing is rather sensitive, you might want to encrypt the data at rest. SQLCypher is a very robust alternative for encrypting SQLite databases. It has versions for every major mobile platform, but it is a paid library. It is available in different editions depending on the level of security and support you need.</li>
<li>Couchbase Mobile,Originally known as Membase, Couchbase is an open source distributed NoSQL database. It is particularly interesting in offline scenarios due to its ability to synchronize back and forth with Couchbase Mobile along with the addition of a sync gateway. It supports the main mobile platforms including Xamarin and PhoneGap, and provides local file encryption.</li>
<li>Meteor,<a href="https://www.meteor.com/">Meteor</a>is an open source platform for building web applications, with built in support for Live Updates. Meteor is based on the open source Node.js platform and MongoDB. It comes with a publish-subscriber mechanism that enables Meteor to propagate changes on the data to every connected clients in real-time.</li>
</ul>


<p>It supports mobile all platforms through hybrid tools like PhoneGap and Cordova.</p>

<h2>Summary</h2>

<p>In times where mobile users are starting to expect the same level of user experience in enterprise applications as they do on their personal consumer applications, offline Support can no longer be ignored. Providing the right level of support for offline scenarios will dramatically improve the mobile application user’s experience and be vital for employee’s productivity.</p>

<p>Keep in mind the security aspects of storing data locally in your device, and try to not to underestimate the impact that your application can have on your users battery.</p>

<h2>reference</h2>

<ul>
<li><a href="http://www.infoq.com/articles/mobile-apps-offline-support">Mobile Apps Offline Support</a></li>
<li><a href="https://www.youtube.com/watch?v=BlkJzgjzL0c">Android Application Architecture</a></li>
<li><a href="https://github.com/yigit/dev-summit-architecture-demo">dev-summit-architecture-demo</a></li>
<li><a href="http://www.infoq.com/cn/articles/mobile-apps-offline-support">为移动应用提供离线支持</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Clean Architecture]]></title>
    <link href="http://Solarex.github.io/blog/2016/03/13/the-clean-architecture/"/>
    <updated>2016-03-13T23:57:00+08:00</updated>
    <id>http://Solarex.github.io/blog/2016/03/13/the-clean-architecture</id>
    <content type="html"><![CDATA[<center><img src="http://Solarex.github.io/images/clean_arch.jpg"></center>


<p>Over the last several years we’ve seen a whole range of ideas regarding the architecture of systems. These include:</p>

<ul>
<li><a href="http://alistair.cockburn.us/Hexagonal+architecture">Hexagonal Architecture</a> (a.k.a. Ports and Adapters) by Alistair Cockburn and adopted by Steve Freeman, and Nat Pryce in their wonderful book <a href="http://www.amazon.com/Growing-Object-Oriented-Software-Guided-Tests/dp/0321503627">Growing Object Oriented Software</a>.</li>
<li><a href="http://jeffreypalermo.com/blog/the-onion-architecture-part-1/">Onion Architecture</a> by Jeffrey Palermo</li>
<li><a href="http://blog.8thlight.com/uncle-bob/2011/09/30/Screaming-Architecture.html">Screaming Architecture</a> from a blog of mine last year</li>
<li><a href="http://www.amazon.com/Lean-Architecture-Agile-Software-Development/dp/0470684208/">DCI</a> from James Coplien, and Trygve Reenskaug.</li>
<li><a href="http://www.amazon.com/Object-Oriented-Software-Engineering-Approach/dp/0201544350">BCE</a> by Ivar Jacobson from his book Object Oriented Software Engineering: A Use-Case Driven Approach</li>
</ul>


<!-- more -->


<p>Though these architectures all vary somewhat in their details, they are very similar. They all have the same objective, which is the separation of concerns. They all achieve this separation by dividing the software into layers. Each has at least one layer for business rules, and another for interfaces.</p>

<p>Each of these architectures produce systems that are:</p>

<ul>
<li>Independent of Frameworks. The architecture does not depend on the existence of some library of feature laden software. This allows you to use such frameworks as tools, rather than having to cram your system into their limited constraints.</li>
<li>Testable. The business rules can be tested without the UI, Database, Web Server, or any other external element.</li>
<li>Independent of UI. The UI can change easily, without changing the rest of the system. A Web UI could be replaced with a console UI, for example, without changing the business rules.</li>
<li>Independent of Database. You can swap out Oracle or SQL Server, for Mongo, BigTable, CouchDB, or something else. Your business rules are not bound to the database.</li>
<li>Independent of any external agency. In fact your business rules simply don’t know anything at all about the outside world.</li>
</ul>


<p>The diagram at the top of this article is an attempt at integrating all these architectures into a single actionable idea.</p>

<h2>The Dependency Rule</h2>

<p>The concentric circles represent different areas of software. In general, the further in you go, the higher level the software becomes. The outer circles are mechanisms. The inner circles are policies.</p>

<p>The overriding rule that makes this architecture work is The Dependency Rule. This rule says that source code dependencies can only point inwards. Nothing in an inner circle can know anything at all about something in an outer circle. In particular, the name of something declared in an outer circle must not be mentioned by the code in the an inner circle. That includes, functions, classes. variables, or any other named software entity.</p>

<p>By the same token, data formats used in an outer circle should not be used by an inner circle, especially if those formats are generate by a framework in an outer circle. We don’t want anything in an outer circle to impact the inner circles.</p>

<h2>Entities</h2>

<p>Entities encapsulate Enterprise wide business rules. An entity can be an object with methods, or it can be a set of data structures and functions. It doesn’t matter so long as the entities could be used by many different applications in the enterprise.</p>

<p>If you don’t have an enterprise, and are just writing a single application, then these entities are the business objects of the application. They encapsulate the most general and high-level rules. They are the least likely to change when something external changes. For example, you would not expect these objects to be affected by a change to page navigation, or security. No operational change to any particular application should affect the entity layer.</p>

<h2>Use Cases</h2>

<p>The software in this layer contains application specific business rules. It encapsulates and implements all of the use cases of the system. These use cases orchestrate the flow of data to and from the entities, and direct those entities to use their enterprise wide business rules to achieve the goals of the use case.</p>

<p>We do not expect changes in this layer to affect the entities. We also do not expect this layer to be affected by changes to externalities such as the database, the UI, or any of the common frameworks. This layer is isolated from such concerns.</p>

<p>We do, however, expect that changes to the operation of the application will affect the use-cases and therefore the software in this layer. If the details of a use-case change, then some code in this layer will certainly be affected.</p>

<h2>Interface Adapters</h2>

<p>The software in this layer is a set of adapters that convert data from the format most convenient for the use cases and entities, to the format most convenient for some external agency such as the Database or the Web. It is this layer, for example, that will wholly contain the MVC architecture of a GUI. The Presenters, Views, and Controllers all belong in here. The models are likely just data structures that are passed from the controllers to the use cases, and then back from the use cases to the presenters and views.</p>

<p>Similarly, data is converted, in this layer, from the form most convenient for entities and use cases, into the form most convenient for whatever persistence framework is being used. i.e. The Database. No code inward of this circle should know anything at all about the database. If the database is a SQL database, then all the SQL should be restricted to this layer, and in particular to the parts of this layer that have to do with the database.</p>

<p>Also in this layer is any other adapter necessary to convert data from some external form, such as an external service, to the internal form used by the use cases and entities.</p>

<h2>Frameworks and Drivers</h2>

<p>The outermost layer is generally composed of frameworks and tools such as the Database, the Web Framework, etc. Generally you don’t write much code in this layer other than glue code that communicates to the next circle inwards.</p>

<p>This layer is where all the details go. The Web is a detail. The database is a detail. We keep these things on the outside where they can do little harm.</p>

<h2>Only Four Circles?</h2>

<p>No, the circles are schematic. You may find that you need more than just these four. There’s no rule that says you must always have just these four. However, The Dependency Rule always applies. Source code dependencies always point inwards. As you move inwards the level of abstraction increases. The outermost circle is low level concrete detail. As you move inwards the software grows more abstract, and encapsulates higher level policies. The inner most circle is the most general.</p>

<h2>Crossing boundaries</h2>

<p>At the lower right of the diagram is an example of how we cross the circle boundaries. It shows the Controllers and Presenters communicating with the Use Cases in the next layer. Note the flow of control. It begins in the controller, moves through the use case, and then winds up executing in the presenter. Note also the source code dependencies. Each one of them points inwards towards the use cases.</p>

<p>We usually resolve this apparent contradiction by using the Dependency Inversion Principle. In a language like Java, for example, we would arrange interfaces and inheritance relationships such that the source code dependencies oppose the flow of control at just the right points across the boundary.</p>

<p>For example, consider that the use case needs to call the presenter. However, this call must not be direct because that would violate The Dependency Rule: No name in an outer circle can be mentioned by an inner circle. So we have the use case call an interface (Shown here as Use Case Output Port) in the inner circle, and have the presenter in the outer circle implement it.</p>

<p>The same technique is used to cross all the boundaries in the architectures. We take advantage of dynamic polymorphism to create source code dependencies that oppose the flow of control so that we can conform to The Dependency Rule no matter what direction the flow of control is going in.</p>

<h2>What data crosses the boundaries.</h2>

<p>Typically the data that crosses the boundaries is simple data structures. You can use basic structs or simple Data Transfer objects if you like. Or the data can simply be arguments in function calls. Or you can pack it into a hashmap, or construct it into an object. The important thing is that isolated, simple, data structures are passed across the boundaries. We don’t want to cheat and pass Entities or Database rows. We don’t want the data structures to have any kind of dependency that violates The Dependency Rule.</p>

<p>For example, many database frameworks return a convenient data format in response to a query. We might call this a RowStructure. We don’t want to pass that row structure inwards across a boundary. That would violate The Dependency Rule because it would force an inner circle to know something about an outer circle.</p>

<p>So when we pass data across a boundary, it is always in the form that is most convenient for the inner circle.</p>

<h2>Conclusion</h2>

<p>Conforming to these simple rules is not hard, and will save you a lot of headaches going forward. By separating the software into layers, and conforming to The Dependency Rule, you will create a system that is intrinsically testable, with all the benefits that implies. When any of the external parts of the system become obsolete, like the database, or the web framework, you can replace those obsolete elements with a minimum of fuss.</p>

<h2>reference</h2>

<ul>
<li><a href="http://blog.8thlight.com/uncle-bob/2012/08/13/the-clean-architecture.html">The Clean Architecture</a></li>
<li><a href="http://blog.csdn.net/bboyfeiyu/article/details/44560155">一种更清晰的Android架构</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Android Handler Memory Leaks]]></title>
    <link href="http://Solarex.github.io/blog/2016/02/25/android-handler-memory-leaks/"/>
    <updated>2016-02-25T19:58:00+08:00</updated>
    <id>http://Solarex.github.io/blog/2016/02/25/android-handler-memory-leaks</id>
    <content type="html"><![CDATA[<p>Android uses Java as a platform for development. This helps us with many low level issues including memory management, platform type dependencies, and so on. However we still sometimes get crashes with OutOfMemory. So where’s the garbage collector?</p>

<p>I’m going to focus on one of the cases where big objects in memory can’t be cleared for a lengthy period of time. This case is not ultimately a memory leak &ndash; objects will be collected at some point &ndash; so we sometimes ignore it. This is not advisable as it can sometimes lead to OOM errors.</p>

<p>The case I’m describing is the Handler leak, which is usually detected as a warning by Lint.</p>

<!-- more -->


<h2>Basic Example</h2>

<center><img src="http://Solarex.github.io/images/anonymous_runnable_code.png"></center>


<p>This is a very basic activity. Notice that this anonymous <code>Runnable</code> has been posted to the <code>Handler</code> with a very long delay. We’ll run it and rotate the phone couple of times, then dump memory and analyze it.</p>

<center><img src="http://Solarex.github.io/images/anonymous_runnable_memory_analyze.png"></center>


<p>We have seven activities in memory now. This is definitely not good. Let’s find out why GC is not able to clear them.ps.The query I made to get a list of all Activities remaining in memory was created in OQL (Object Query Language), which is very simple, yet powerful.</p>

<center><img src="http://Solarex.github.io/images/anonymous_runnable_memory_explained.png"></center>


<p>As you can see, one of the activities is referenced by this$0. This is an indirect reference from the anonymous class to the owner class. This$0 is referenced by callback, which is then referenced by a chain of next’s of Message back to the main thread.Any time you create a non-static class inside the owner class, Java creates an indirect reference to the owner.</p>

<p>Once you post <code>Runnable</code> or <code>Message</code> into Handler, it’s then stored in list of <code>Message</code> commands referenced from <code>LooperThread</code> until the message is executed. Posting delayed messages is a clear leak for at least the time of the delay value. Posting without delay may cause a temporary leak as well if the queue of messages is large.</p>

<h2>Static Runnable Solution</h2>

<p>Let’s try to overcome a memory leak by getting rid of <code>this$0</code>, by converting the anonymous class to static.</p>

<center><img src="http://Solarex.github.io/images/static_class.png"></center>


<p>Run, rotate and get the memory dump.</p>

<center><img src="http://Solarex.github.io/images/static_class_memory_analyze.png"></center>


<p>What, again? Let’s see who keeps referring to Activities.</p>

<center><img src="http://Solarex.github.io/images/static_class_memory_analyze_explained.png"></center>


<p>Take a look at the bottom of the tree &ndash; activity is kept as a reference to mContext inside mTextView of our DoneRunnable class. Using static inner classes is not enough to overcome memory leaks, however. We need to do more.</p>

<h2>Static Runnable With WeakReference</h2>

<p>Let’s continue using iterative fixes and get rid of the reference to TextView, which keeps activity from being destroyed.</p>

<center><img src="http://Solarex.github.io/images/static_class_with_WeakRef.png"></center>


<p>Note that we are keeping WeakReference to TextView, and let’s run, rotate and dump memory.Be careful with WeakReferences. They can be null at any moment, so resolve them first to a local variable (hard reference) and then check to null before use.</p>

<center><img src="http://Solarex.github.io/images/static_class_with_WeakRef_memory_analyze.png"></center>


<p>Hooray! Only one activity instance. This solves our memory problem.</p>

<p>So for this approach we should:</p>

<ul>
<li>Use static inner classes (or outer classes)</li>
<li>Use <code>WeakReference</code> to all objects manipulated from <code>Handler/Runnable</code></li>
</ul>


<p>If you compare this code to the initial code, you might find a big difference in readability and code clearance. The initial code is much shorter and much clearer, and you’ll see that eventually, text in textView will be changed to ‘Done’. No need to browse the code to realise that.</p>

<p>Writing this much boilerplate code is very tedious, especially if postDelayed is set to a short time, such as 50ms. There are better and clearer solutions.</p>

<h2>Cleanup All Messages onDestroy</h2>

<p><code>Handler</code> class has an interesting feature &ndash; <code>removeCallbacksAndMessages</code> &ndash; which can accept <code>null</code> as argument. It will remove all <code>Runnables</code> and <code>Messages</code> posted to a particular handler. Let’s use it in <code>onDestroy</code>.</p>

<center><img src="http://Solarex.github.io/images/removeCallbacks.png"></center>


<p>Let’s run, rotate and dump memory.</p>

<center><img src="http://Solarex.github.io/images/removeCallbacks_memory_analyze.png"></center>


<p>Good! Only one instance.</p>

<p>This approach is way better than the previous one, as it keeps code clear and readable. The only overhead is to remember to clear all messages on activity/fragment destroy.</p>

<p>I have one more solution which, if you’re lazy like me, you might like even more. :)</p>

<h2>Use WeakHandler</h2>

<p>The Badoo team came up with the interesting idea of introducing <code>WeakHandler</code> &ndash; a class that behaves as <code>Handler</code>, but is way safer.</p>

<p>It takes advantage of hard and weak references to get rid of memory leaks. I will describe the idea in detail a bit later, but let’s look at the code first:</p>

<center><img src="http://Solarex.github.io/images/WeakHandler.png"></center>


<p>Very similar to the original code apart from one small difference &ndash; instead of using <code>android.os.Handler</code>, I’ve used <code>WeakHandler</code>. Let’s run, rotate and dump memory:</p>

<center><img src="http://Solarex.github.io/images/WeakHandler_memory_analyze.png"></center>


<p>Nice, isn’t it? The code is cleaner than ever, and memory is clean as well! :)</p>

<p>To use it, just add dependency to your <code>build.gradle</code>:</p>

<p>```groovy
repositories {</p>

<pre><code>maven {
    repositories {
        url 'https://oss.sonatype.org/content/repositories/releases/'
    }
}
</code></pre>

<p>}</p>

<p>dependencies {</p>

<pre><code>compile 'com.badoo.mobile:android-weak-handler:1.0'
</code></pre>

<p>}
```</p>

<p>And import it in your java class:</p>

<p><code>java
import com.badoo.mobile.util.WeakHandler;
</code></p>

<p>Visit Badoo’s github page, where you can fork it, or study it’s <a href="https://github.com/badoo/android-weak-handler">source code</a>.</p>

<h2>WeakHandler. How it works</h2>

<p>The main aim of <code>WeakHandler</code> is to keep <code>Runnables/Messages</code> hard-referenced while <code>WeakHandler</code> is also hard-referenced. Once it can be GC-ed, all messages should go away as well.</p>

<p>Here is a simple diagram that demonstrates differences between using normal <code>Handler</code> and <code>WeakHandler</code> to post anonymous runnables:</p>

<center><img src="http://Solarex.github.io/images/WeakHandler_how_it_works.png"></center>


<p>Looking at the top diagram, <code>Activity</code> keeps a reference to <code>Handler</code>, which posts <code>Runnable</code> (puts it into queue of <code>Messages</code> referenced from <code>Thread</code>). Everything is fine except the indirect reference from <code>Runnable</code> to <code>Activity</code>. While <code>Message</code> is in the queue, all graphs can’t be garbage-collected.</p>

<p>By comparison, in the bottom diagram <code>Activity</code> holds <code>WeakHandler</code>, which keeps <code>Handler</code> inside. When we ask it to post <code>Runnable</code>, it is wrapped into <code>WeakRunnable</code> and posted. So the <code>Message</code> queue keeps reference only to <code>WeakRunnable</code>. <code>WeakRunnable</code> keeps weak reference to the desired <code>Runnable</code>, so the <code>Runnable</code> can be garbage-collected.</p>

<p>Another little trick is that <code>WeakHandler</code> still keeps a hard reference to the desired <code>Runnable</code>, to prevent it from being garbage-collected while <code>WeakRunnable</code> is active.</p>

<p>The side-effect of using <code>WeakHandler</code> is that all messages and runnables may not be executed if <code>WeakHandler</code> has been garbage-collected. To prevent that, just keep a reference to it from <code>Activity</code>. Once <code>Activity</code> is ready to be collected, all graphs with <code>WeakHandler</code> will collected as well.</p>

<h2>Conclusions</h2>

<p>Using <code>postDelayed</code> in Android requires additional effort. To achieve it we came up with three different methods:</p>

<ul>
<li>Use a static inner <code>Runnable/Handler</code> with <code>WeakReference</code> to owner class</li>
<li>Clear all messages from <code>Handler</code> in <code>onDestroy</code> of <code>Activity/Fragment</code></li>
<li>Use <a href="https://github.com/badoo/android-weak-handler">WeakHandler</a> from Badoo as a silver bullet</li>
</ul>


<p>It’s up to you to choose your preferred technique. The second seems very reasonable, but needs some extra work. The third is my favourite, obviously, but it require some attention as well &ndash; <code>WeakHandler</code> should not be used without hard reference from outside.</p>

<p>```java
package com.badoo.mobile.util;</p>

<p>import android.os.Handler;
import android.os.Looper;
import android.os.Message;
import android.support.annotation.NonNull;
import android.support.annotation.Nullable;
import android.support.annotation.VisibleForTesting;</p>

<p>import java.lang.ref.WeakReference;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;</p>

<p>/<em>*
 * Memory safer implementation of android.os.Handler
 * <p/>
 * Original implementation of Handlers always keeps hard reference to handler in queue of execution.
 * If you create anonymous handler and post delayed message into it, it will keep all parent class
 * for that time in memory even if it could be cleaned.
 * <p/>
 * This implementation is trickier, it will keep WeakReferences to runnables and messages,
 * and GC could collect them once WeakHandler instance is not referenced any more
 * <p/>
 *
 * @see android.os.Handler
 *
 * Created by Dmytro Voronkevych on 17/06/2014.
 </em>/
@SuppressWarnings(&ldquo;unused&rdquo;)
public class WeakHandler {</p>

<pre><code>private final Handler.Callback mCallback; // hard reference to Callback. We need to keep callback in memory
private final ExecHandler mExec;
private Lock mLock = new ReentrantLock();
@SuppressWarnings("ConstantConditions")
@VisibleForTesting
final ChainedRef mRunnables = new ChainedRef(mLock, null);

/**
 * Default constructor associates this handler with the {@link Looper} for the
 * current thread.
 *
 * If this thread does not have a looper, this handler won't be able to receive messages
 * so an exception is thrown.
 */
public WeakHandler() {
    mCallback = null;
    mExec = new ExecHandler();
}

/**
 * Constructor associates this handler with the {@link Looper} for the
 * current thread and takes a callback interface in which you can handle
 * messages.
 *
 * If this thread does not have a looper, this handler won't be able to receive messages
 * so an exception is thrown.
 *
 * @param callback The callback interface in which to handle messages, or null.
 */
public WeakHandler(@Nullable Handler.Callback callback) {
    mCallback = callback; // Hard referencing body
    mExec = new ExecHandler(new WeakReference&lt;&gt;(callback)); // Weak referencing inside ExecHandler
}

/**
 * Use the provided {@link Looper} instead of the default one.
 *
 * @param looper The looper, must not be null.
 */
public WeakHandler(@NonNull Looper looper) {
    mCallback = null;
    mExec = new ExecHandler(looper);
}

/**
 * Use the provided {@link Looper} instead of the default one and take a callback
 * interface in which to handle messages.
 *
 * @param looper The looper, must not be null.
 * @param callback The callback interface in which to handle messages, or null.
 */
public WeakHandler(@NonNull Looper looper, @NonNull Handler.Callback callback) {
    mCallback = callback;
    mExec = new ExecHandler(looper, new WeakReference&lt;&gt;(callback));
}

/**
 * Causes the Runnable r to be added to the message queue.
 * The runnable will be run on the thread to which this handler is
 * attached.
 *
 * @param r The Runnable that will be executed.
 *
 * @return Returns true if the Runnable was successfully placed in to the
 *         message queue.  Returns false on failure, usually because the
 *         looper processing the message queue is exiting.
 */
public final boolean post(@NonNull Runnable r) {
    return mExec.post(wrapRunnable(r));
}

/**
 * Causes the Runnable r to be added to the message queue, to be run
 * at a specific time given by &lt;var&gt;uptimeMillis&lt;/var&gt;.
 * &lt;b&gt;The time-base is {@link android.os.SystemClock#uptimeMillis}.&lt;/b&gt;
 * The runnable will be run on the thread to which this handler is attached.
 *
 * @param r The Runnable that will be executed.
 * @param uptimeMillis The absolute time at which the callback should run,
 *         using the {@link android.os.SystemClock#uptimeMillis} time-base.
 *
 * @return Returns true if the Runnable was successfully placed in to the
 *         message queue.  Returns false on failure, usually because the
 *         looper processing the message queue is exiting.  Note that a
 *         result of true does not mean the Runnable will be processed -- if
 *         the looper is quit before the delivery time of the message
 *         occurs then the message will be dropped.
 */
public final boolean postAtTime(@NonNull Runnable r, long uptimeMillis) {
    return mExec.postAtTime(wrapRunnable(r), uptimeMillis);
}

/**
 * Causes the Runnable r to be added to the message queue, to be run
 * at a specific time given by &lt;var&gt;uptimeMillis&lt;/var&gt;.
 * &lt;b&gt;The time-base is {@link android.os.SystemClock#uptimeMillis}.&lt;/b&gt;
 * The runnable will be run on the thread to which this handler is attached.
 *
 * @param r The Runnable that will be executed.
 * @param uptimeMillis The absolute time at which the callback should run,
 *         using the {@link android.os.SystemClock#uptimeMillis} time-base.
 *
 * @return Returns true if the Runnable was successfully placed in to the
 *         message queue.  Returns false on failure, usually because the
 *         looper processing the message queue is exiting.  Note that a
 *         result of true does not mean the Runnable will be processed -- if
 *         the looper is quit before the delivery time of the message
 *         occurs then the message will be dropped.
 *
 * @see android.os.SystemClock#uptimeMillis
 */
public final boolean postAtTime(Runnable r, Object token, long uptimeMillis) {
    return mExec.postAtTime(wrapRunnable(r), token, uptimeMillis);
}

/**
 * Causes the Runnable r to be added to the message queue, to be run
 * after the specified amount of time elapses.
 * The runnable will be run on the thread to which this handler
 * is attached.
 *
 * @param r The Runnable that will be executed.
 * @param delayMillis The delay (in milliseconds) until the Runnable
 *        will be executed.
 *
 * @return Returns true if the Runnable was successfully placed in to the
 *         message queue.  Returns false on failure, usually because the
 *         looper processing the message queue is exiting.  Note that a
 *         result of true does not mean the Runnable will be processed --
 *         if the looper is quit before the delivery time of the message
 *         occurs then the message will be dropped.
 */
public final boolean postDelayed(Runnable r, long delayMillis) {
    return mExec.postDelayed(wrapRunnable(r), delayMillis);
}

/**
 * Posts a message to an object that implements Runnable.
 * Causes the Runnable r to executed on the next iteration through the
 * message queue. The runnable will be run on the thread to which this
 * handler is attached.
 * &lt;b&gt;This method is only for use in very special circumstances -- it
 * can easily starve the message queue, cause ordering problems, or have
 * other unexpected side-effects.&lt;/b&gt;
 *
 * @param r The Runnable that will be executed.
 *
 * @return Returns true if the message was successfully placed in to the
 *         message queue.  Returns false on failure, usually because the
 *         looper processing the message queue is exiting.
 */
public final boolean postAtFrontOfQueue(Runnable r) {
    return mExec.postAtFrontOfQueue(wrapRunnable(r));
}

/**
 * Remove any pending posts of Runnable r that are in the message queue.
 */
public final void removeCallbacks(Runnable r) {
    final WeakRunnable runnable = mRunnables.remove(r);
    if (runnable != null) {
        mExec.removeCallbacks(runnable);
    }
}

/**
 * Remove any pending posts of Runnable &lt;var&gt;r&lt;/var&gt; with Object
 * &lt;var&gt;token&lt;/var&gt; that are in the message queue.  If &lt;var&gt;token&lt;/var&gt; is null,
 * all callbacks will be removed.
 */
public final void removeCallbacks(Runnable r, Object token) {
    final WeakRunnable runnable = mRunnables.remove(r);
    if (runnable != null) {
        mExec.removeCallbacks(runnable, token);
    }
}

/**
 * Pushes a message onto the end of the message queue after all pending messages
 * before the current time. It will be received in callback,
 * in the thread attached to this handler.
 *
 * @return Returns true if the message was successfully placed in to the
 *         message queue.  Returns false on failure, usually because the
 *         looper processing the message queue is exiting.
 */
public final boolean sendMessage(Message msg) {
    return mExec.sendMessage(msg);
}

/**
 * Sends a Message containing only the what value.
 *
 * @return Returns true if the message was successfully placed in to the
 *         message queue.  Returns false on failure, usually because the
 *         looper processing the message queue is exiting.
 */
public final boolean sendEmptyMessage(int what) {
    return mExec.sendEmptyMessage(what);
}

/**
 * Sends a Message containing only the what value, to be delivered
 * after the specified amount of time elapses.
 * @see #sendMessageDelayed(android.os.Message, long)
 *
 * @return Returns true if the message was successfully placed in to the
 *         message queue.  Returns false on failure, usually because the
 *         looper processing the message queue is exiting.
 */
public final boolean sendEmptyMessageDelayed(int what, long delayMillis) {
    return mExec.sendEmptyMessageDelayed(what, delayMillis);
}

/**
 * Sends a Message containing only the what value, to be delivered
 * at a specific time.
 * @see #sendMessageAtTime(android.os.Message, long)
 *
 * @return Returns true if the message was successfully placed in to the
 *         message queue.  Returns false on failure, usually because the
 *         looper processing the message queue is exiting.
 */
public final boolean sendEmptyMessageAtTime(int what, long uptimeMillis) {
    return mExec.sendEmptyMessageAtTime(what, uptimeMillis);
}

/**
 * Enqueue a message into the message queue after all pending messages
 * before (current time + delayMillis). You will receive it in
 * callback, in the thread attached to this handler.
 *
 * @return Returns true if the message was successfully placed in to the
 *         message queue.  Returns false on failure, usually because the
 *         looper processing the message queue is exiting.  Note that a
 *         result of true does not mean the message will be processed -- if
 *         the looper is quit before the delivery time of the message
 *         occurs then the message will be dropped.
 */
public final boolean sendMessageDelayed(Message msg, long delayMillis) {
    return mExec.sendMessageDelayed(msg, delayMillis);
}

/**
 * Enqueue a message into the message queue after all pending messages
 * before the absolute time (in milliseconds) &lt;var&gt;uptimeMillis&lt;/var&gt;.
 * &lt;b&gt;The time-base is {@link android.os.SystemClock#uptimeMillis}.&lt;/b&gt;
 * You will receive it in callback, in the thread attached
 * to this handler.
 *
 * @param uptimeMillis The absolute time at which the message should be
 *         delivered, using the
 *         {@link android.os.SystemClock#uptimeMillis} time-base.
 *
 * @return Returns true if the message was successfully placed in to the
 *         message queue.  Returns false on failure, usually because the
 *         looper processing the message queue is exiting.  Note that a
 *         result of true does not mean the message will be processed -- if
 *         the looper is quit before the delivery time of the message
 *         occurs then the message will be dropped.
 */
public boolean sendMessageAtTime(Message msg, long uptimeMillis) {
    return mExec.sendMessageAtTime(msg, uptimeMillis);
}

/**
 * Enqueue a message at the front of the message queue, to be processed on
 * the next iteration of the message loop.  You will receive it in
 * callback, in the thread attached to this handler.
 * &lt;b&gt;This method is only for use in very special circumstances -- it
 * can easily starve the message queue, cause ordering problems, or have
 * other unexpected side-effects.&lt;/b&gt;
 *
 * @return Returns true if the message was successfully placed in to the
 *         message queue.  Returns false on failure, usually because the
 *         looper processing the message queue is exiting.
 */
public final boolean sendMessageAtFrontOfQueue(Message msg) {
    return mExec.sendMessageAtFrontOfQueue(msg);
}

/**
 * Remove any pending posts of messages with code 'what' that are in the
 * message queue.
 */
public final void removeMessages(int what) {
    mExec.removeMessages(what);
}

/**
 * Remove any pending posts of messages with code 'what' and whose obj is
 * 'object' that are in the message queue.  If &lt;var&gt;object&lt;/var&gt; is null,
 * all messages will be removed.
 */
public final void removeMessages(int what, Object object) {
    mExec.removeMessages(what, object);
}

/**
 * Remove any pending posts of callbacks and sent messages whose
 * &lt;var&gt;obj&lt;/var&gt; is &lt;var&gt;token&lt;/var&gt;.  If &lt;var&gt;token&lt;/var&gt; is null,
 * all callbacks and messages will be removed.
 */
public final void removeCallbacksAndMessages(Object token) {
    mExec.removeCallbacksAndMessages(token);
}

/**
 * Check if there are any pending posts of messages with code 'what' in
 * the message queue.
 */
public final boolean hasMessages(int what) {
    return mExec.hasMessages(what);
}

/**
 * Check if there are any pending posts of messages with code 'what' and
 * whose obj is 'object' in the message queue.
 */
public final boolean hasMessages(int what, Object object) {
    return mExec.hasMessages(what, object);
}

public final Looper getLooper() {
    return mExec.getLooper();
}

private WeakRunnable wrapRunnable(@NonNull Runnable r) {
    //noinspection ConstantConditions
    if (r == null) {
        throw new NullPointerException("Runnable can't be null");
    }
    final ChainedRef hardRef = new ChainedRef(mLock, r);
    mRunnables.insertAfter(hardRef);
    return hardRef.wrapper;
}

private static class ExecHandler extends Handler {
    private final WeakReference&lt;Handler.Callback&gt; mCallback;

    ExecHandler() {
        mCallback = null;
    }

    ExecHandler(WeakReference&lt;Handler.Callback&gt; callback) {
        mCallback = callback;
    }

    ExecHandler(Looper looper) {
        super(looper);
        mCallback = null;
    }

    ExecHandler(Looper looper, WeakReference&lt;Handler.Callback&gt; callback) {
        super(looper);
        mCallback = callback;
    }

    @Override
    public void handleMessage(@NonNull Message msg) {
        if (mCallback == null) {
            return;
        }
        final Handler.Callback callback = mCallback.get();
        if (callback == null) { // Already disposed
            return;
        }
        callback.handleMessage(msg);
    }
}

static class WeakRunnable implements Runnable {
    private final WeakReference&lt;Runnable&gt; mDelegate;
    private final WeakReference&lt;ChainedRef&gt; mReference;

    WeakRunnable(WeakReference&lt;Runnable&gt; delegate, WeakReference&lt;ChainedRef&gt; reference) {
        mDelegate = delegate;
        mReference = reference;
    }

    @Override
    public void run() {
        final Runnable delegate = mDelegate.get();
        final ChainedRef reference = mReference.get();
        if (reference != null) {
            reference.remove();
        }
        if (delegate != null) {
            delegate.run();
        }
    }
}

static class ChainedRef {
    @Nullable
    ChainedRef next;
    @Nullable
    ChainedRef prev;
    @NonNull
    final Runnable runnable;
    @NonNull
    final WeakRunnable wrapper;

    @NonNull
    Lock lock;

    public ChainedRef(@NonNull Lock lock, @NonNull Runnable r) {
        this.runnable = r;
        this.lock = lock;
        this.wrapper = new WeakRunnable(new WeakReference&lt;&gt;(r), new WeakReference&lt;&gt;(this));
    }

    public WeakRunnable remove() {
        lock.lock();
        try {
            if (prev != null) {
                prev.next = next;
            }
            if (next != null) {
                next.prev = prev;
            }
            prev = null;
            next = null;
        } finally {
            lock.unlock();
        }
        return wrapper;
    }

    public void insertAfter(@NonNull ChainedRef candidate) {
        lock.lock();
        try {
            if (this.next != null) {
                this.next.prev = candidate;
            }

            candidate.next = this.next;
            this.next = candidate;
            candidate.prev = this;
        } finally {
            lock.unlock();
        }
    }

    @Nullable
    public WeakRunnable remove(Runnable obj) {
        lock.lock();
        try {
            ChainedRef curr = this.next; // Skipping head
            while (curr != null) {
                if (curr.runnable == obj) { // We do comparison exactly how Handler does inside
                    return curr.remove();
                }
                curr = curr.next;
            }
        } finally {
            lock.unlock();
        }
        return null;
    }
}
</code></pre>

<p>}
```</p>

<h2>reference</h2>

<ul>
<li><a href="https://techblog.badoo.com/blog/2014/08/28/android-handler-memory-leaks">Android Handler Memory Leaks</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RecyclerView Animation part II]]></title>
    <link href="http://Solarex.github.io/blog/2016/02/12/recyclerview-animation-part-ii/"/>
    <updated>2016-02-12T00:47:00+08:00</updated>
    <id>http://Solarex.github.io/blog/2016/02/12/recyclerview-animation-part-ii</id>
    <content type="html"><![CDATA[<p>In the first article, I’ve covered the main idea on how predictive animations run in RecyclerView. There is actually a lot more going on to achieve this simplicity (for the LayoutManager). Here are some important points that you should know about.</p>

<p>RecyclerView keeps some children attached although they have been removed by the LayoutManager. How does it work? Does it invalidate the contract between the LayoutManager and RecyclerView?</p>

<p>Yes it does ‘kind of’ violate the contract with LayoutManager, but:</p>

<p>RecyclerView does keep the View as a child of the ViewGroup but hides it from the LayoutManager. Each time LayoutManager calls a method to access its children, RecyclerView takes into account the hidden Views. Lets look at the example at Part 1 where ‘C’ was being removed from the adapter.</p>

<center><img src="http://Solarex.github.io/images/predictive_animations.gif"></center>




<!-- more -->


<p>While ‘C’ is fading out, if LayoutManager calls <code>getChildCount()</code>, RecyclerView returns 6 although it has 7 children. If <code>LayoutManager</code> calls <code>getChildAt(int)</code>, RecyclerView offsets that call properly to skip child ‘C’ (or any hidden children). If LayoutManager calls <code>addView(View, position)</code>, RecyclerView offsets the index properly before calling <code>ViewGroup#addView</code>.</p>

<p>When the animation ends, RecyclerView will remove the View and recycle it.</p>

<p>For more details, you can check <code>ChildHelper</code> internal class.</p>

<p>How does RecyclerView handle item positions in the preLayout pass since they don’t match Adapter contents?</p>

<p>This is doable thanks to the specific notify events added to the Adapter. When Adapter dispatches <code>notify**</code> events, RecyclerView records them and requests a layout to apply them. Any events that arrives before the next layout pass will be applied together.</p>

<p>When <code>onLayout</code> is called by the system, RecyclerView does the following:</p>

<ul>
<li>Reorder update events such that move events are pushed to the end of the list of update ops. Moving move events to the end of the list is a simplification step so I’ll not go into details here. You can check <code>OpReorderer</code> class for details if you are interested.</li>
<li>Process events one by one and update existing ViewHolders’ positions with respect to the update. If a ViewHolder is removed, it is also marked as <code>removed</code>. While doing this, RecyclerView also decides whether the adapter change should be dispatched to the LayoutManager before or after the preLayout step. This decision process is as follows:

<ul>
<li>If it is an <code>add</code> operation, it is deferred because item should not exist in preLayout.</li>
<li>If it is an <code>update</code> or <code>remove</code> operation and if it affects existing ViewHolders, it is postponed. If it does not effect existing ViewHolders, it is dispatched to the LayoutManager because RecyclerView cannot resurrect the previous state of the item (because it does not have a ViewHolder that represents the previous state of that Item).</li>
<li>If it is a <code>move</code> operation, it is deferred because RecyclerView can fake its location in the pre-layout pass. For example, if item at position 3 moved to position 5, RecyclerView can return the View for position 5 in pre-layout when View for position 3 is asked.</li>
<li>RecyclerView rewrites update operations as necessary. For example, if an update or delete operation affects some of the ViewHolders, RecyclerView divides that operation. If an operation should be dispatched to LayoutManager but a deferred operation may affect it, RecyclerView re-orders these operations so that they are still consistent.</li>
</ul>
</li>
</ul>


<p>For example, if there is an Add 1 at 3 operation which is deferred followed by a Remove 1 at 5 operation which cannot be deferred, RecyclerView dispatches it to the LayoutManager as Remove 1 at 4. This is done because the original Remove 1 at 5 was notified by the Adapter after Add 1 at 3 so it includes that item. Since RecyclerView did not tell LayoutManager about the Add 1 at 3, it rewrites the remove operation to be consistent.</p>

<p>This approach makes tracking items dead simple for a LayoutManager. The abstraction between the Adapter and the LayoutManager makes all of this possible, which is why RecyclerView never passes the Adapter to the LayoutManager, instead, provides methods to access Adapter via State and Recycler.</p>

<p>ViewHolders also have their old position, pre layout position and final adapter positions. When <code>ViewHolder#getPosition</code> is called, they return either preLayout position or final adapter position depending on the current layout state (pre or post). LayoutManager doesn’t need to know about this because it will always be consistent with the previous events that were dispatched to the LayoutManager.</p>

<ul>
<li>After Adapter updates are processed, RecyclerView saves positions and dimensions of existing Views which will later be used for animations.</li>
<li>RecyclerView calls <code>LayoutManager#onLayoutChildren</code> for the preLayout step. As I’ve mentioned in the first article, LayoutManager runs its regular layout logic. All it has to do is to layout more items for those which are being deleted or changed (<code>LayoutParams#isItemRemoved</code> , <code>LayoutParams#isItemChanged</code>). As a reminder, the deleted or changed item still ‘appears’ in the Adapter API given to the LayoutManager. This way, LayoutManager simply treats it as any other View (adds, measures, positions etc).</li>
<li>After preLayout is complete, RecyclerView records the positions of the Views again and dispatches the remaining Adapter updates to the LayoutManager.</li>
<li>RecyclerView calls LayoutManager’s <code>onLayout</code> again (postLayout). This time, all item positions match the current contents of the Adapter. LayoutManager runs its regular layout logic again.</li>
<li>After post layout is complete, RecyclerView checks positions of Views again and decides which items are added, removed, changed and moved. It ‘hides’ removed Views and for views not added by the LayoutManager, adds them to the RecyclerView (because they should be animated).</li>
<li>Items which require an animation are passed to the <code>ItemAnimator</code> to start their animations. After the animation is complete, Item Animator calls a callback in RecyclerView which removes and recycles the View if it is no longer necessary.</li>
</ul>


<h3>What happens if LayoutManager keeps some internal data structure using item positions?</h3>

<p>Everything works… kind of :). Thanks to the re-writing of Adapter updates by the RecyclerView, all LayoutManager has to do is to update its own bookkeeping when one of its adapter data changed callbacks is called due to Adapter changes. RecyclerView ensures that these updates are called at the appropriate time and order.</p>

<p>At any time during a layout, if LayoutManager needs to access the adapter for additional data (some custom API), it can call <code>Recycler#convertPreLayoutPositionToPostLayout</code> to get the item’s Adapter position. For example, GridLayoutManager uses this API to get the span size of items.</p>

<h3>What happens if notifyDataSetChanged is called? How do predictive animations run?</h3>

<p>They don’t, which is why <code>notifyDataSetChanged</code> should be your last resort. When <code>notifyDataSetChanged</code> is called on the adapter, RecyclerView does not know where items moved so it cannot properly fake <code>getViewForPosition</code> calls. It simply runs animations as a LayoutTransition would do.</p>

<h2>reference</h2>

<ul>
<li><a href="http://www.birbit.com/recyclerview-animations-part-2-behind-the-scenes/">RecyclerView Animations Part 2 – Behind The Scenes</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RecyclerView Animation part I]]></title>
    <link href="http://Solarex.github.io/blog/2016/02/11/recyclerview-animation-part-i/"/>
    <updated>2016-02-11T00:47:00+08:00</updated>
    <id>http://Solarex.github.io/blog/2016/02/11/recyclerview-animation-part-i</id>
    <content type="html"><![CDATA[<p>ListView is one of the most popular widgets of the Android Framework. It has many features, yet it is fairly complex and hard to modify. As the UX paradigms evolved and phones got faster, its limitations started to overshadow its feature set.</p>

<p>With Lollipop, the Android team decided to release a new widget that will make writing different collection views much easier with a pluggable architecture. Many different behaviors can be controlled easily by implementing simple contracts to change:</p>

<ul>
<li>how items are laid out</li>
<li>animations!</li>
<li>item decorations</li>
<li>recycling strategy</li>
</ul>


<p>This great flexibility comes with the additional complexity of a bigger architecture. Also, there are more things to learn.</p>

<!-- more -->


<p>In this post, I want to deep dive into RecyclerView internals, particularly on how animations work.</p>

<p>On Honeycomb, the Android Framework introduced LayoutTransition, which was a very easy way to animate changes inside a ViewGroup. It works by taking a snapshot of the ViewGroup before and after the layout changes, then creating Animators to move between these two states. This process is fairly similar to what RecyclerView needs to do to animate changes in the adapter.</p>

<center><img src="http://Solarex.github.io/images/trans_man_default.gif" alt="LayoutTransition example"></center>


<p>Unfortunately, lists have one major difference which makes LayoutTransitions a bad fit for their animations. Specifically, items in lists are not the same as views in a ViewGroup. This is an important distinction that needs to be understood to handle animations on “items” while using mechanisms that animate the “views” that show the item contents.</p>

<p>In a normal ViewGroup, if a View is newly added to the View hierarchy, it can be treated like a newly added View and thus it can be animated accordingly (e.g. fade in). For collections, it is a bit different. For example, a View for an item may become visible just because an item before it has been removed from the Adapter. In this case, running a fade in animation for the new item would be misleading because it was already in the list though the view is new because the item just entered the viewport. RecyclerView knows if the item is new or not but it does not know where it was if the item is not new. The same case is valid for disappearing Views, RecyclerView does not know where the view went if it is not removed from the Adapter.</p>

<center><img src="http://Solarex.github.io/images/trans_man_bad.gif" alt="LayoutTransition failure for a list"></center>


<p>To overcome this problem, <code>RecyclerView</code> could ask <code>LayoutManager</code> for the previous location of the new View. Although this would work, it would require some bookkeeping on the <code>LayoutManager</code> end and may not be trivial to calculate for more complex <code>LayoutManagers</code>.</p>

<p>The way that <code>RecyclerView</code> handles animating appearing and disappearing items (that is, animating the appearance and disappearance of views that refer to items that were and are still in the list) is by relying on the <code>LayoutManager</code> to handle predictive layout logic. One one hand, the <code>RecyclerView</code> wants to know where views would have been had they been laid out prior to this change. On the other hand, the <code>RecyclerView</code> wants to know where views would be laid out after this change if the <code>LayoutManager</code> went to the trouble of laying out items that are not currently visible.</p>

<p>To make it easy for the <code>LayoutManager</code> to provide this information, <code>RecyclerView</code> uses a two step layout process when there are adapter changes which should be animated. The mechanisms for handling these predictive layout passes are described below.</p>

<ul>
<li>In the first layout pass (preLayout), RecyclerView asks LayoutManager to layout the previous state with the knowledge of the additional information. For the example above, it would be like requesting “Layout items again, btw, ‘C’ has been removed”. The LayoutManager runs its usual layout step but knowing that ‘C’ will be removed, it lays out View(s) to fill the space left by ‘C’.The cool part of this contract is that RecyclerView still behaves as if ‘C’ is still in the backing Adapter. For example, when LayoutManager asks for the View for position 2, RecyclerView returns ‘C’ (<code>getViewForPosition(2) == View('C')</code>) and if LayoutManager asks for position 4, RecyclerView returns the View for ‘E’ (although ‘D’ is the 4th item in the Adapter). LayoutParams of the returned View has an <code>isItemRemoved</code> method which LayoutManager can use to check if this is a disappearing item.</li>
<li>In the second layout pass (postLayout), RecyclerView asks LayoutManager to re-layout its items. This time, ‘C’ is not in the Adapter anymore. <code>getViewForPosition(2)</code> will return ‘D’ and <code>getViewForPosition(4)</code> will return ‘F’.Keep in mind that the backing item for ‘C’ was already removed from the Adapter, but since RecyclerView has the View representation of it, it can behave as if ‘C’ is still there. In other words, RecyclerView does the bookkeeping for the LayoutManager.</li>
</ul>


<p>Every time <code>onLayoutChildren</code> is called on the <code>LayoutManager</code>, it temporarily detaches all views and lays them out from scratch again. Unchanged Views are returned from the scrap cache so their measurements stay valid, making this relayout fairly cheap and simple.</p>

<center><img src="http://Solarex.github.io/images/pre-layout.jpeg" alt="LinearLayoutManager pre layout result"></center>




<center><img src="http://Solarex.github.io/images/post-layout.jpeg" alt="LinearLayoutManager post layout result"></center>


<p>After these two layout passes, RecyclerView knows where the Views came from so it can run the correct animation.</p>

<center><img src="http://Solarex.github.io/images/predictive_animations.gif" alt="predictive animations"></center>


<p>You might ask: The View ‘C’ was not laid out by the LayoutManager, how come it is still visible?</p>

<p>To be clear, ‘C’ was laid out by the LayoutManager in the pre-layout pass because it looked like it was in the Adapter. It is true that ‘C’ was not laid out by the LayoutManager in the post-layout pass because it does not exist in the Adapter anymore. It is also true for the LayoutManager that ‘C’ is not its child anymore but not true for the RecyclerView. When a View is removed by the LayoutManager, if ItemAnimator wants to animate it, RecyclerView keeps it as a child (so that animations can run properly). More details on this in Part2.</p>

<h2>Disappearing Items</h2>

<p>With these two layout passes, RecyclerView is able to animate new Views properly. But now, there is another problem with Views that are disappearing. Consider the following case where a new item is added to the list, pushing some other items outside the visible area. This is how it would look with LayoutTransitions:</p>

<center><img src="http://Solarex.github.io/images/layout_transition_add.gif" alt="layout transition add"></center>


<p>When ‘X’ was added after ‘A’, it pushed ‘F’ outside the screen. Since LayoutManager will not layout ‘F’, LayoutTransition thinks it has been removed from the UI and runs a fade out animation for it. In reality, ‘F’ is still in the adapter but has been pushed out of bounds.</p>

<p>To solve this issue, RecyclerView provides an additional API to LayoutManager to get this information. At the end of a postLayout pass, LayoutManager can call <code>getScrapList</code> to get list of Views which are in this situation (not laid out by the <code>LayoutManager</code> but still present in the <code>Adapter</code>). Then, it lays out these views as well, as if the size of RecyclerView was big enough to show them.</p>

<center><img src="http://Solarex.github.io/images/add_post_layout_with_frame.png"></center>


<p>One important detail is that, since these Views are not necessary after their animations are complete, <code>LayoutManager</code> calls <code>addDisappearingView</code> instead of <code>addView</code>. This gives the clue to the RecyclerView that this View should be removed after its animations is complete. RecyclerView also adds the View to the list of hidden views so that it will disappear from LayoutManager’s children list as soon as postLayout method returns. This way, LayoutManager can forget about it.</p>

<center><img src="http://Solarex.github.io/images/predictive_add.gif"></center>


<p>Initially, at least for a LinearLayoutManager, you might think that it can calculate where the Views came from or where they went (if disappeared) and thus won’t need a two pass layout calculation. Unfortunately, there are many edge cases when multiple types of adapter changes happen in the same layout pass. In addition to that, for a more complex LayoutManager, it is not always trivial to calculate where an item would be placed (e.g. StaggeredGridLayout). This approach removes all burden from the LayoutManager and it can support proper animations with little effort.</p>

<p>So far, I’ve covered the main idea on how predictive animations run in RecyclerView. There is actually a lot more going on to achieve this simplicity (for the LayoutManager). You can read about how all this works in Part 2 – Behind The Scenes.</p>

<h2>reference</h2>

<ul>
<li><a href="http://www.birbit.com/recyclerview-animations-part-1-how-animations-work/">RecyclerView Animations Part 1 – How Animations Work</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
